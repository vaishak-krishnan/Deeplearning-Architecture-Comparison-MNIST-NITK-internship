{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPsKoIwEvRO1p+wivBl+lEw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaishak-krishnan/Deeplearning-Architecture-Comparison-MNIST-NITK-internship/blob/main/Deeplearning_Architecture_Comparison_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBmYpm29dPY5",
        "outputId": "375b034f-2d52-4547-bc41-bb2814d1ee1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "422/422 [==============================] - 4s 6ms/step - loss: 0.3692 - accuracy: 0.8889 - val_loss: 0.1071 - val_accuracy: 0.9685\n",
            "Epoch 2/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1003 - accuracy: 0.9691 - val_loss: 0.0691 - val_accuracy: 0.9788\n",
            "Epoch 3/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0720 - accuracy: 0.9774 - val_loss: 0.0625 - val_accuracy: 0.9802\n",
            "Epoch 4/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0566 - accuracy: 0.9823 - val_loss: 0.0670 - val_accuracy: 0.9785\n",
            "Epoch 5/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0473 - accuracy: 0.9851 - val_loss: 0.0528 - val_accuracy: 0.9847\n",
            "Epoch 6/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0404 - accuracy: 0.9867 - val_loss: 0.0510 - val_accuracy: 0.9852\n",
            "Epoch 7/10\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.0350 - accuracy: 0.9889 - val_loss: 0.0462 - val_accuracy: 0.9860\n",
            "Epoch 8/10\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0307 - accuracy: 0.9901 - val_loss: 0.0500 - val_accuracy: 0.9858\n",
            "Epoch 9/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0269 - accuracy: 0.9908 - val_loss: 0.0556 - val_accuracy: 0.9832\n",
            "Epoch 10/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0251 - accuracy: 0.9919 - val_loss: 0.0434 - val_accuracy: 0.9887\n",
            "Epoch 1/10\n",
            "422/422 [==============================] - 8s 13ms/step - loss: 0.1646 - accuracy: 0.9483 - val_loss: 0.0685 - val_accuracy: 0.9793\n",
            "Epoch 2/10\n",
            "422/422 [==============================] - 5s 13ms/step - loss: 0.0433 - accuracy: 0.9864 - val_loss: 0.0363 - val_accuracy: 0.9895\n",
            "Epoch 3/10\n",
            "422/422 [==============================] - 6s 13ms/step - loss: 0.0283 - accuracy: 0.9912 - val_loss: 0.0366 - val_accuracy: 0.9890\n",
            "Epoch 4/10\n",
            "422/422 [==============================] - 5s 13ms/step - loss: 0.0222 - accuracy: 0.9928 - val_loss: 0.0298 - val_accuracy: 0.9918\n",
            "Epoch 5/10\n",
            "422/422 [==============================] - 5s 12ms/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 0.0332 - val_accuracy: 0.9908\n",
            "Epoch 6/10\n",
            "422/422 [==============================] - 6s 13ms/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.0266 - val_accuracy: 0.9928\n",
            "Epoch 7/10\n",
            "422/422 [==============================] - 5s 12ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.0293 - val_accuracy: 0.9933\n",
            "Epoch 8/10\n",
            "422/422 [==============================] - 5s 12ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.0269 - val_accuracy: 0.9937\n",
            "Epoch 9/10\n",
            "422/422 [==============================] - 5s 13ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.0266 - val_accuracy: 0.9925\n",
            "Epoch 10/10\n",
            "422/422 [==============================] - 5s 12ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.0448 - val_accuracy: 0.9917\n",
            "Epoch 1/10\n",
            "422/422 [==============================] - 72s 81ms/step - loss: 0.3390 - accuracy: 0.9149 - val_loss: 1.7137 - val_accuracy: 0.4260\n",
            "Epoch 2/10\n",
            "422/422 [==============================] - 29s 69ms/step - loss: 0.0707 - accuracy: 0.9786 - val_loss: 0.2088 - val_accuracy: 0.9427\n",
            "Epoch 3/10\n",
            "422/422 [==============================] - 30s 70ms/step - loss: 0.0445 - accuracy: 0.9860 - val_loss: 0.0796 - val_accuracy: 0.9778\n",
            "Epoch 4/10\n",
            "422/422 [==============================] - 30s 71ms/step - loss: 0.0343 - accuracy: 0.9892 - val_loss: 0.1037 - val_accuracy: 0.9773\n",
            "Epoch 5/10\n",
            "422/422 [==============================] - 30s 71ms/step - loss: 0.0417 - accuracy: 0.9874 - val_loss: 0.0778 - val_accuracy: 0.9778\n",
            "Epoch 6/10\n",
            "422/422 [==============================] - 30s 71ms/step - loss: 0.0560 - accuracy: 0.9845 - val_loss: 0.0790 - val_accuracy: 0.9810\n",
            "Epoch 7/10\n",
            "422/422 [==============================] - 34s 81ms/step - loss: 0.0313 - accuracy: 0.9900 - val_loss: 0.0544 - val_accuracy: 0.9855\n",
            "Epoch 8/10\n",
            "422/422 [==============================] - 33s 79ms/step - loss: 0.0526 - accuracy: 0.9849 - val_loss: 0.5518 - val_accuracy: 0.8798\n",
            "Epoch 9/10\n",
            "422/422 [==============================] - 32s 75ms/step - loss: 0.0514 - accuracy: 0.9842 - val_loss: 0.0536 - val_accuracy: 0.9860\n",
            "Epoch 10/10\n",
            "422/422 [==============================] - 33s 77ms/step - loss: 0.0284 - accuracy: 0.9914 - val_loss: 0.0801 - val_accuracy: 0.9793\n",
            "Epoch 1/10\n",
            "422/422 [==============================] - 115s 109ms/step - loss: 0.1293 - accuracy: 0.9591 - val_loss: 4.5251 - val_accuracy: 0.2067\n",
            "Epoch 2/10\n",
            "422/422 [==============================] - 37s 88ms/step - loss: 0.0488 - accuracy: 0.9849 - val_loss: 0.0964 - val_accuracy: 0.9772\n",
            "Epoch 3/10\n",
            "422/422 [==============================] - 38s 89ms/step - loss: 0.0338 - accuracy: 0.9896 - val_loss: 0.0431 - val_accuracy: 0.9868\n",
            "Epoch 4/10\n",
            "422/422 [==============================] - 37s 87ms/step - loss: 0.0273 - accuracy: 0.9911 - val_loss: 0.0813 - val_accuracy: 0.9762\n",
            "Epoch 5/10\n",
            "422/422 [==============================] - 37s 88ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.0431 - val_accuracy: 0.9882\n",
            "Epoch 6/10\n",
            "422/422 [==============================] - 37s 87ms/step - loss: 0.0204 - accuracy: 0.9939 - val_loss: 0.0827 - val_accuracy: 0.9770\n",
            "Epoch 7/10\n",
            "422/422 [==============================] - 41s 97ms/step - loss: 0.0204 - accuracy: 0.9936 - val_loss: 0.0581 - val_accuracy: 0.9820\n",
            "Epoch 8/10\n",
            "422/422 [==============================] - 39s 91ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.0596 - val_accuracy: 0.9845\n",
            "Epoch 9/10\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.0703 - val_accuracy: 0.9787\n",
            "Epoch 10/10\n",
            "422/422 [==============================] - 38s 89ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.2429 - val_accuracy: 0.9470\n",
            "+----------+--------------------+\n",
            "|  Model   |   Test Accuracy    |\n",
            "+----------+--------------------+\n",
            "|  LeNet   | 0.9884999990463257 |\n",
            "|   VGG    | 0.9905999898910522 |\n",
            "| ResNet50 | 0.975600004196167  |\n",
            "| DenseNet | 0.9387999773025513 |\n",
            "+----------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "#importing libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, UpSampling2D\n",
        "from tensorflow.keras.applications import ResNet50, DenseNet121\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tabulate import tabulate\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the images\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# Reshape for Conv2D layers\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Resize images to 32x32 for ResNet and DenseNet\n",
        "x_train_resized = np.array([tf.image.resize(img, (32, 32)) for img in x_train])\n",
        "x_test_resized = np.array([tf.image.resize(img, (32, 32)) for img in x_test])\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# LeNet architecture\n",
        "def create_lenet():\n",
        "    model = Sequential([\n",
        "        Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(16, kernel_size=(5, 5), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(120, activation='relu'),\n",
        "        Dense(84, activation='relu'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# VGG-like architecture\n",
        "def create_vgg():\n",
        "    model = Sequential([\n",
        "        Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
        "        Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# ResNet50 architecture\n",
        "def create_resnet():\n",
        "    base_model = ResNet50(weights=None, include_top=False, input_shape=(32, 32, 1))\n",
        "    x = Flatten()(base_model.output)\n",
        "    x = Dense(10, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=x)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# DenseNet architecture\n",
        "def create_densenet():\n",
        "    base_model = DenseNet121(weights=None, include_top=False, input_shape=(32, 32, 1))\n",
        "    x = Flatten()(base_model.output)\n",
        "    x = Dense(10, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=x)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Training parameters with 10 epochs with batch size of 128\n",
        "epochs = 10\n",
        "batch_size = 128\n",
        "\n",
        "# Traing and evaluation :  LeNet\n",
        "lenet = create_lenet()\n",
        "lenet.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1)\n",
        "lenet_score = lenet.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Traing and evaluation :   VGG\n",
        "vgg = create_vgg()\n",
        "vgg.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1)\n",
        "vgg_score = vgg.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Traing and evaluation :  ResNet50\n",
        "resnet = create_resnet()\n",
        "resnet.fit(x_train_resized, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1)\n",
        "resnet_score = resnet.evaluate(x_test_resized, y_test, verbose=0)\n",
        "\n",
        "# Traing and evaluation :  DenseNet\n",
        "densenet = create_densenet()\n",
        "densenet.fit(x_train_resized, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1)\n",
        "densenet_score = densenet.evaluate(x_test_resized, y_test, verbose=0)\n",
        "\n",
        "# results in a table\n",
        "results = [\n",
        "    [\"LeNet\", lenet_score[1]],\n",
        "    [\"VGG\", vgg_score[1]],\n",
        "    [\"ResNet50\", resnet_score[1]],\n",
        "    [\"DenseNet\", densenet_score[1]]\n",
        "]\n",
        "\n",
        "print(tabulate(results, headers=[\"Model\", \"Test Accuracy\"], tablefmt=\"pretty\"))\n"
      ]
    }
  ]
}